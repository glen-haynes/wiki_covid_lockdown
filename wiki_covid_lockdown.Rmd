---
title: "Scrape Wikipedia_COVID-19_pandemic_lockdowns"
output: html_document
author: Glen Haynes
params:
  use_html_from_file: FALSE
---

```{r}
use_html_from_file <- params$use_html_from_file
```

```{r}
library(dplyr)
library(reticulate)
library(purrr)
```

## Pull Lockdown Tables from Wikipedia ##
#  HTML file can be specified in the 'source' parameter as a web URL or called from a local directory  #
# rtrn_tbl can be specified as one of, 'locked', 'not_locked', or 'both'. #
# Code was adapted from https://simpleanalytical.com/how-to-web-scrape-wikipedia-python-urllib-beautiful-soup-pandas #

```{r,  warning=FALSE}
use_python("c/Miniconda3/python")
wiki_covid_lockdown <- import("wiki_covid_lockdown")

wiki_lock_status <- wiki_covid_lockdown$wiki_covid_lockdown()

wiki_lock <- wiki_lock_status[[1]] %>%
  map(~sapply(.x, function(y){
      as.character(y) %>% gsub("^\\s+|\\s+$", "", .)
    })) %>% bind_cols()

wiki_no_lock <- wiki_lock_status[[2]] %>%
  map(~sapply(.x, function(y){
      as.character(y) %>% gsub("^\\s+|\\s+$", "", .)
    })) %>% bind_cols()
```
